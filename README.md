# ğŸ“¡ Flight Delay ETL Pipeline  
*A modular, production-style ETL workflow for airline delay analytics*

This project implements a complete **Extractâ€“Transformâ€“Load (ETL) pipeline** to process U.S. flight delay data.  
It simulates a *real-world data engineering system* â€” starting from raw CSV ingestion, applying feature engineering and cleansing, loading into a relational database, and running SQL-based analysis.

The pipeline is fully modular, logged, reproducible, and ready for extension (dashboard, API, orchestration tools, etc.).

---

## ğŸ§­ Overview

The goal of this project is to build a **clean, maintainable ETL pipeline** that supports analytical questions such as:

- Which airlines have the highest or lowest delays?  
- Which airports perform best and worst?  
- What delay patterns exist across months or years?  
- How much do weather, security, NAS, and airline operations contribute to delays?  
- Which *airline + airport combinations* have the worst passenger experience?

The implementation demonstrates practical data engineering principles:

âœ” Modular scripts (extract â†’ transform â†’ load â†’ orchestrate)  
âœ” Logging and error handling  
âœ” SQL schema design + indexing  
âœ” SQL analytics on processed data  
âœ” Reproducible end-to-end execution  

---

## ğŸ—‚ï¸ Dataset

**Airline_Delay_Cause.csv** 

Monthly statistics per airline & airport, including:

- arrival delays  
- number of delayed, cancelled, diverted flights  
- delay minutes by category:  
  - carrier  
  - weather  
  - NAS  
  - security  
  - late aircraft  
- airport & carrier identifiers  
- date information (year, month)

- **Original source (filtered from Jan'25 - Jul'25)**  
  ğŸ‘‰ https://www.transtats.bts.gov/ot_delay/OT_DelayCause1.asp?20=E 
- raw data is stored in:
  `data/raw/`
- Cleaned and engineered output saved to:
  `data/processed/flights_cleaned.csv`
  
---

## ğŸ§± Architecture

```
             data/raw/*.csv
                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   PHASE 2 â€” Extract   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  PHASE 3 â€” Transform   â”‚
        â”‚  â€¢ feature engineering â”‚
        â”‚  â€¢ delay rates         â”‚
        â”‚  â€¢ cleaning/imputation â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚     PHASE 4 â€” Load     â”‚
        â”‚ SQLite DB + indexes    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ PHASE 5 â€” Orchestrationâ”‚
        â”‚ run_pipeline.py        â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   PHASE 6 â€” Analysis   â”‚
        â”‚ SQL insights/queries   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```

---

## ğŸ“ Repository Structure

```
flight-delay-etl/
â”œâ”€â”€ config/
â”‚ â””â”€â”€ schema.sql
â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ raw/
â”‚ â”‚ â”œâ”€â”€ Airline_Delay_Cause.csv
â”‚ â”‚ â””â”€â”€ Download_Column_Definitions.xlsx
â”‚ â””â”€â”€ processed/
â”‚ â””â”€â”€ flights_cleaned.csv
â”‚
â”œâ”€â”€ db/
â”‚ â””â”€â”€ flights.db
â”‚
â”œâ”€â”€ logs/
â”‚ â””â”€â”€ pipeline.log
â”‚
â”œâ”€â”€ notebooks/
â”‚ â””â”€â”€ flight_delay_pipeline.ipynb
â”‚
â”œâ”€â”€ scripts/
â”‚ â”œâ”€â”€ extract.py
â”‚ â”œâ”€â”€ transform.py
â”‚ â”œâ”€â”€ load.py
â”‚ â”œâ”€â”€ run_pipeline.py
â”‚ â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ sql_queries/
â”‚ â””â”€â”€ queries.sql
â”‚
â”œâ”€â”€ README.md

```
---

## ğŸ”§ Tech Stack

- Python  
- Pandas  
- SQLite 
- SQL
- Python Logging

---

## âš™ï¸ Pipeline Components

### **PHASE 2 â€” Extract**  
`scripts/extract.py`

- Loads raw CSV from URL or local path  
- Optional sampling  
- Logs row counts  
- Returns raw DataFrame

### **PHASE 3 â€” Transform**  
`scripts/transform.py`

- Converting `year+month` â†’ proper `datetime`
- Calculating delay rates
- Imputing missing counts
- Normalizing numeric types
- Creating delay_category (good / moderate / poor)
- Filling invalid values
- Saves cleaned CSV

### **PHASE 4 â€” Load**  
`scripts/load.py`

Schema defined in `config/schema.sql`

Created SQLite DB: `flights.db`

Inlcudes:
- 26+ fields
- Strong typing for counts & delay metrics
- Indexes:
  - (carrier, year, month)
  - (airport, date)

### **PHASE 5 â€” Orchestration**  
`scripts/run_pipeline.py`

Runs the complete workflow:
1. Extract
2. Transform
3. Load
4. Log end-to-end success or failure

### **PHASE 6 â€” SQL Analysis**
`sql_queries/queries.sql` includes:

- Top 10 airlines by avg delay minutes
- Worst airports by highest delay %
- Best airports by lowest delay %
- Most reliable airlines
- Delay trend by month
- Delay cause breakdown
- Worst airlineâ€“airport combinations

---

## âœ¨ Key Skills

- Building scalable ingestion and cleaning pipelines
- Cleaning and preparing real-world datasets
- Feature engineering on datetime and categorical variables  
- Designing SQL schema and using indexes  
- Structuring Python code for modular ETL tasks  
- Logging & reproducibility
- Analytical SQL for insights

---

## ğŸ”® Next Steps

- Add Power BI / Streamlit dashboard
- Introduce Airflow or Prefect orchestration
- Build REST API with FastAPI
- Add pytest unit tests
- Parameterize pipeline with config files
